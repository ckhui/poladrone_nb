{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TrainingRunnner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- setup dataloader\n",
    "- start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:53.625791Z",
     "start_time": "2020-07-09T07:38:53.620515Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:53.686596Z",
     "start_time": "2020-07-09T07:38:53.631295Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:54.727802Z",
     "start_time": "2020-07-09T07:38:53.690476Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "from exp.nb_CustomDataLoader import Detection_dataset\n",
    "from exp.nb_LoggingModule import custom_init_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:54.737233Z",
     "start_time": "2020-07-09T07:38:54.731365Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "import os, sys\n",
    "# base = \"/Users/ckh/Documents/Poladrone/nb\"\n",
    "base = \"D:/YoloV5_Hui/poladrone_nb\"\n",
    "sys.path.append(base + \"/ref/pytorchYOLOv4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:55.126634Z",
     "start_time": "2020-07-09T07:38:54.744261Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "from ref.pytorchYOLOv4.train import *\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:55.135140Z",
     "start_time": "2020-07-09T07:38:55.128923Z"
    },
    "code_folding": [
     0
    ],
    "hide_input": false,
    "hide_output": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "def custom_collate(batch):\n",
    "    images = []\n",
    "    bboxes = []\n",
    "    for i, (img, box) in enumerate(batch):\n",
    "        images.append([img])\n",
    "        if len(box) == 0:\n",
    "            continue\n",
    "        box = np.concatenate((box, [[i]]*len(box)), 1)\n",
    "        bboxes.append(box)\n",
    "        \n",
    "    images = np.concatenate(images, axis=0)\n",
    "    images = images.transpose(0, 3, 1, 2)\n",
    "    images = torch.from_numpy(images).div(255.0)\n",
    "            \n",
    "    bboxes = np.concatenate(bboxes)\n",
    "\n",
    "    bboxes = torch.from_numpy(bboxes)\n",
    "    return images, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:55.197780Z",
     "start_time": "2020-07-09T07:38:55.137940Z"
    },
    "code_folding": [
     1,
     2
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "class Custom_Yolo_loss(nn.Module):\n",
    "    def __init__(self, n_classes=80, n_anchors=3, device=None, batch=2):\n",
    "        super(Custom_Yolo_loss, self).__init__()\n",
    "        self.device = device\n",
    "        self.strides = [8, 16, 32]\n",
    "        image_size = 416\n",
    "        self.n_classes = n_classes\n",
    "        self.n_anchors = n_anchors\n",
    "\n",
    "        self.anchors = [[12, 16], [19, 36], [40, 28], [36, 75], [76, 55], [72, 146], [142, 110], [192, 243], [459, 401]]\n",
    "        self.anch_masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "        self.ignore_thre = 0.5\n",
    "\n",
    "        self.masked_anchors, self.ref_anchors, self.grid_x, self.grid_y, self.anchor_w, self.anchor_h = [], [], [], [], [], []\n",
    "\n",
    "        for i in range(3):\n",
    "            all_anchors_grid = [(w / self.strides[i], h / self.strides[i]) for w, h in self.anchors]\n",
    "            masked_anchors = np.array([all_anchors_grid[j] for j in self.anch_masks[i]], dtype=np.float32)\n",
    "            ref_anchors = np.zeros((len(all_anchors_grid), 4), dtype=np.float32)\n",
    "            ref_anchors[:, 2:] = np.array(all_anchors_grid, dtype=np.float32)\n",
    "            ref_anchors = torch.from_numpy(ref_anchors)\n",
    "            # calculate pred - xywh obj cls\n",
    "            fsize = image_size // self.strides[i]\n",
    "            grid_x = torch.arange(fsize, dtype=torch.float).repeat(batch, 3, fsize, 1).to(device)\n",
    "            grid_y = torch.arange(fsize, dtype=torch.float).repeat(batch, 3, fsize, 1).permute(0, 1, 3, 2).to(device)\n",
    "            anchor_w = torch.from_numpy(masked_anchors[:, 0]).repeat(batch, fsize, fsize, 1).permute(0, 3, 1, 2).to(\n",
    "                device)\n",
    "            anchor_h = torch.from_numpy(masked_anchors[:, 1]).repeat(batch, fsize, fsize, 1).permute(0, 3, 1, 2).to(\n",
    "                device)\n",
    "            \n",
    "            self.masked_anchors.append(masked_anchors)\n",
    "            self.ref_anchors.append(ref_anchors)\n",
    "            self.grid_x.append(grid_x)\n",
    "            self.grid_y.append(grid_y)\n",
    "            self.anchor_w.append(anchor_w)\n",
    "            self.anchor_h.append(anchor_h)\n",
    "\n",
    "    def build_target(self, pred, labels, batchsize, fsize, n_ch, output_id):\n",
    "\n",
    "        # target assignment\n",
    "        tgt_mask = torch.zeros(batchsize, self.n_anchors, fsize, fsize, 4 + self.n_classes).to(device=self.device)\n",
    "        obj_mask = torch.ones(batchsize, self.n_anchors, fsize, fsize).to(device=self.device)\n",
    "        tgt_scale = torch.zeros(batchsize, self.n_anchors, fsize, fsize, 2).to(self.device)\n",
    "        target = torch.zeros(batchsize, self.n_anchors, fsize, fsize, n_ch).to(self.device)\n",
    "\n",
    "            # labels = labels.cpu().data\n",
    "        # nlabel = (labels.sum(dim=2) > 0).sum(dim=1)  # number of objects\n",
    "\n",
    "        # batches_labels =  labels[:,-1]\n",
    "        # nlabel = [(batches_labels == i).sum() for i in range(batchsize)]\n",
    "\n",
    "        truth_x_all = (labels[:, 2] + labels[:, 0]) / (self.strides[output_id] * 2)\n",
    "        truth_y_all = (labels[:, 3] + labels[:, 1]) / (self.strides[output_id] * 2)\n",
    "        truth_w_all = (labels[:, 2] - labels[:, 0]) / self.strides[output_id]\n",
    "        truth_h_all = (labels[:, 3] - labels[:, 1]) / self.strides[output_id]\n",
    "        truth_i_all = truth_x_all.to(torch.int16).cpu().numpy()\n",
    "        truth_j_all = truth_y_all.to(torch.int16).cpu().numpy()\n",
    "\n",
    "        for b in range(batchsize):\n",
    "\n",
    "            img_index = (labels[:,-1] == b).cpu()\n",
    "            n = int(img_index.sum())\n",
    "            if n == 0:\n",
    "                continue\n",
    "\n",
    "            truth_box = torch.zeros(n, 4).to(self.device)\n",
    "            truth_box[:, 2] = truth_w_all[img_index]\n",
    "            truth_box[:, 3] = truth_h_all[img_index]\n",
    "            truth_i = truth_i_all[img_index]\n",
    "            truth_j = truth_j_all[img_index]\n",
    "\n",
    "            # calculate iou between truth and reference anchors\n",
    "            anchor_ious_all = bboxes_iou(truth_box.cpu(), self.ref_anchors[output_id])\n",
    "            best_n_all = anchor_ious_all.argmax(dim=1)\n",
    "            best_n = best_n_all % 3\n",
    "            best_n_mask = ((best_n_all == self.anch_masks[output_id][0]) |\n",
    "                           (best_n_all == self.anch_masks[output_id][1]) |\n",
    "                           (best_n_all == self.anch_masks[output_id][2]))\n",
    "            \n",
    "            if sum(best_n_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            truth_box[:, 0] = truth_x_all[img_index]\n",
    "            truth_box[:, 1] = truth_y_all[img_index]\n",
    "\n",
    "            pred_ious = bboxes_iou(pred[b].view(-1, 4), truth_box, xyxy=False)\n",
    "            pred_best_iou, _ = pred_ious.max(dim=1)\n",
    "            pred_best_iou = (pred_best_iou > self.ignore_thre)\n",
    "            pred_best_iou = pred_best_iou.view(pred[b].shape[:3])\n",
    "            # set mask to zero (ignore) if pred matches truth\n",
    "            obj_mask[b] = ~ pred_best_iou\n",
    "\n",
    "            for ti in range(best_n.shape[0]):\n",
    "                if best_n_mask[ti] == 1:\n",
    "                    i, j = truth_i[ti], truth_j[ti]\n",
    "                    a = best_n[ti]\n",
    "                    obj_mask[b, a, j, i] = 1\n",
    "                    tgt_mask[b, a, j, i, :] = 1\n",
    "                    target[b, a, j, i, 0] = truth_x_all[ti] - truth_x_all[ti].to(torch.int16).to(torch.float)\n",
    "                    target[b, a, j, i, 1] = truth_y_all[ti] - truth_y_all[ti].to(torch.int16).to(torch.float)\n",
    "                    target[b, a, j, i, 2] = torch.log(\n",
    "                        truth_w_all[ti] / torch.Tensor(self.masked_anchors[output_id])[best_n[ti], 0] + 1e-16)\n",
    "                    target[b, a, j, i, 3] = torch.log(\n",
    "                        truth_h_all[ti] / torch.Tensor(self.masked_anchors[output_id])[best_n[ti], 1] + 1e-16)\n",
    "                    target[b, a, j, i, 4] = 1\n",
    "                    target[b, a, j, i, 5 + labels[ti, 4].to(torch.int16).cpu().numpy()] = 1\n",
    "                    tgt_scale[b, a, j, i, :] = torch.sqrt(2 - truth_w_all[ti] * truth_h_all[ti] / fsize / fsize)\n",
    "        \n",
    "        return obj_mask, tgt_mask, tgt_scale, target\n",
    "\n",
    "    def forward(self, xin, labels=None):\n",
    "        loss, loss_xy, loss_wh, loss_obj, loss_cls, loss_l2 = 0, 0, 0, 0, 0, 0   \n",
    "        \n",
    "        for output_id, output in enumerate(xin):\n",
    "            \n",
    "            batchsize = output.shape[0]\n",
    "            fsize = output.shape[2]\n",
    "\n",
    "            n_ch = 5 + self.n_classes\n",
    "\n",
    "            output = output.view(batchsize, self.n_anchors, n_ch, fsize, fsize)\n",
    "            output = output.permute(0, 1, 3, 4, 2)  # .contiguous()\n",
    "\n",
    "            # logistic activation for xy, obj, cls\n",
    "            output[..., np.r_[:2, 4:n_ch]] = torch.sigmoid(output[..., np.r_[:2, 4:n_ch]])\n",
    "\n",
    "            pred = output[..., :4].clone()\n",
    "            pred[..., 0] += self.grid_x[output_id]\n",
    "            pred[..., 1] += self.grid_y[output_id]\n",
    "            pred[..., 2] = torch.exp(pred[..., 2]) * self.anchor_w[output_id]\n",
    "            pred[..., 3] = torch.exp(pred[..., 3]) * self.anchor_h[output_id]\n",
    "\n",
    "            ## get label for this batch only    \n",
    "            obj_mask, tgt_mask, tgt_scale, target = self.build_target(pred, labels, batchsize, fsize, n_ch, output_id)\n",
    "\n",
    "            # loss calculation\n",
    "            output[..., 4] *= obj_mask\n",
    "            output[..., np.r_[0:4, 5:n_ch]] *= tgt_mask\n",
    "            output[..., 2:4] *= tgt_scale\n",
    "\n",
    "            target[..., 4] *= obj_mask\n",
    "            target[..., np.r_[0:4, 5:n_ch]] *= tgt_mask\n",
    "            target[..., 2:4] *= tgt_scale\n",
    "\n",
    "            \n",
    "            loss_xy += F.binary_cross_entropy(input=output[..., :2], target=target[..., :2],\n",
    "                                              weight=tgt_scale * tgt_scale, reduction='sum')\n",
    "            loss_wh += F.mse_loss(input=output[..., 2:4], target=target[..., 2:4], reduction='sum') / 2\n",
    "            loss_obj += F.binary_cross_entropy(input=output[..., 4], target=target[..., 4], reduction='sum')\n",
    "            loss_cls += F.binary_cross_entropy(input=output[..., 5:], target=target[..., 5:], reduction='sum')\n",
    "            loss_l2 += F.mse_loss(input=output, target=target, reduction='sum')\n",
    "\n",
    "        loss = loss_xy + loss_wh + loss_obj + loss_cls\n",
    "\n",
    "        return loss, loss_xy, loss_wh, loss_obj, loss_cls, loss_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:55.248280Z",
     "start_time": "2020-07-09T07:38:55.203718Z"
    },
    "code_folding": [
     1,
     38,
     64,
     65
    ],
    "hide_input": false,
    "hide_output": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "def custom_train(train_dataset, val_dataset, model, device, config, epochs=5, batch_size=1, save_cp=True, log_step=20, val_epoch=10, img_scale=0.5):\n",
    "#     train_dataset = Yolo_dataset(config.train_label, config)\n",
    "#     val_dataset = Yolo_dataset(config.val_label, config)\n",
    "\n",
    "    n_train = len(train_dataset)\n",
    "    n_val = len(val_dataset)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch // config.subdivisions, shuffle=True,\n",
    "                              num_workers=0, pin_memory=False, drop_last=True, collate_fn=custom_collate)\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch // config.subdivisions, shuffle=False, num_workers=0,\n",
    "                            pin_memory=False, drop_last=True, collate_fn=custom_collate)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=config.TRAIN_TENSORBOARD_DIR,\n",
    "                           filename_suffix=f'OPT_{config.TRAIN_OPTIMIZER}_LR_{config.learning_rate}_BS_{config.batch}_Sub_{config.subdivisions}_Size_{config.width}',\n",
    "                           comment=f'OPT_{config.TRAIN_OPTIMIZER}_LR_{config.learning_rate}_BS_{config.batch}_Sub_{config.subdivisions}_Size_{config.width}')\n",
    "\n",
    "    max_itr = config.TRAIN_EPOCHS * n_train\n",
    "    # global_step = cfg.TRAIN_MINEPOCH * n_train\n",
    "    global_step = 0\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {config.batch}\n",
    "        Subdivisions:    {config.subdivisions}\n",
    "        Learning rate:   {config.learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_cp}\n",
    "        Device:          {device.type}\n",
    "        Images size:     {config.width}\n",
    "        Optimizer:       {config.TRAIN_OPTIMIZER}\n",
    "        Dataset classes: {config.classes}\n",
    "        Train label path:{config.train_label}\n",
    "        Pretrained:\n",
    "    ''')\n",
    "\n",
    "    # learning rate setup\n",
    "    def burnin_schedule(i):\n",
    "        if i < config.burn_in:\n",
    "            factor = pow(i / config.burn_in, 4)\n",
    "        elif i < config.steps[0]:\n",
    "            factor = 1.0\n",
    "        elif i < config.steps[1]:\n",
    "            factor = 0.1\n",
    "        else:\n",
    "            factor = 0.01\n",
    "        return factor\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate / config.batch, betas=(0.9, 0.999), eps=1e-08)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, burnin_schedule)\n",
    "\n",
    "    criterion = Custom_Yolo_loss(n_classes=config.classes, device=device, batch=config.batch // config.subdivisions)\n",
    "    \n",
    "    # scheduler = ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience=6, min_lr=1e-7)\n",
    "    # scheduler = CosineAnnealingWarmRestarts(optimizer, 0.001, 1e-6, 20)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_step = 0\n",
    "\n",
    "        model.train()\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img', ncols=50) as pbar:\n",
    "            for i, batch in enumerate(train_loader):\n",
    "                global_step += 1\n",
    "                epoch_step += 1\n",
    "                images = batch[0]\n",
    "                bboxes = batch[1]\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                bboxes = bboxes.to(device=device)\n",
    "                \n",
    "                bboxes_pred = model(images)\n",
    "                loss, loss_xy, loss_wh, loss_obj, loss_cls, loss_l2 = criterion(bboxes_pred, bboxes)\n",
    "                # loss = loss / config.subdivisions\n",
    "                loss.backward()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if global_step  % config.subdivisions == 0:\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    model.zero_grad()\n",
    "\n",
    "                if global_step % (log_step * config.subdivisions) == 0:\n",
    "                    writer.add_scalar('train/Loss', loss.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_xy', loss_xy.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_wh', loss_wh.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_obj', loss_obj.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_cls', loss_cls.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_l2', loss_l2.item(), global_step)\n",
    "                    writer.add_scalar('lr', scheduler.get_last_lr()[0]* config.batch, global_step)\n",
    "                    \n",
    "                    pbar.set_postfix(**{'loss (batch)': loss.item(), \n",
    "                                        'loss_xy': loss_xy.item(),\n",
    "                                        'loss_wh': loss_wh.item(),\n",
    "                                        'loss_obj': loss_obj.item(),\n",
    "                                        'loss_cls': loss_cls.item(),\n",
    "                                        'loss_l2': loss_l2.item(),\n",
    "                                        'lr': scheduler.get_lr()[0] * config.batch\n",
    "                                        })\n",
    "                    \n",
    "                    logging.debug('Train step_{}: loss : {},loss xy : {},loss wh : {},'\n",
    "                                  'loss obj : {}，loss cls : {},loss l2 : {},lr : {}'\n",
    "                                  .format(global_step, loss.item(), loss_xy.item(),\n",
    "                                          loss_wh.item(), loss_obj.item(),\n",
    "                                          loss_cls.item(), loss_l2.item(),\n",
    "                                          scheduler.get_last_lr()[0] * config.batch))\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "            \n",
    "        if save_cp:\n",
    "            try:\n",
    "                os.mkdir(config.checkpoints)\n",
    "                logging.info('Created checkpoint directory')\n",
    "            except OSError:\n",
    "                pass\n",
    "            torch.save(model.state_dict(), os.path.join(config.checkpoints, f'Yolov4_epoch{epoch + 1}.pth'))\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved !')\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        if (epochs % val_epoch) > 0:\n",
    "            continue\n",
    "            \n",
    "        model.eval()\n",
    "        with tqdm(total=n_val, desc=f'Val: Epoch {epoch + 1}', unit='img', ncols=50) as pbar:\n",
    "            val_loss = 0\n",
    "            for j, batch in enumerate(val_loader):      \n",
    "                images = batch[0]\n",
    "                bboxes = batch[1]\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                bboxes = bboxes.to(device=device)\n",
    "\n",
    "                bboxes_pred = model(images)\n",
    "                loss, loss_xy, loss_wh, loss_obj, loss_cls, loss_l2 = criterion(bboxes_pred, bboxes)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                pbar.set_postfix_str(\"Loss:%f.2\"%(val_loss))\n",
    "                    \n",
    "            writer.add_scalar('val/Loss', val_loss, global_step)\n",
    "                \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:55.454590Z",
     "start_time": "2020-07-09T07:38:55.253373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'palm1_npt': 0, 'palm1_byt': 1, 'palm2_mtl': 2} 121\n"
     ]
    }
   ],
   "source": [
    "from config.config import Cfg\n",
    "\n",
    "# data_list = \"/Users/ckh/OneDrive - Default Directory/Hui_Wan/train_npt.txt\"\n",
    "data_list = \"D:/YoloV5_Hui/Dataset/train_npt.txt\"\n",
    "\n",
    "dataset = Detection_dataset(data_list, Cfg)\n",
    "print(dataset.names, len(dataset))\n",
    "\n",
    "## without augmentation\n",
    "val_dataset = Detection_dataset(data_list, Cfg, val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:55.462515Z",
     "start_time": "2020-07-09T07:38:55.456550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log file path:log\\log_2020-07-13_10-16-46.txt\n"
     ]
    }
   ],
   "source": [
    "logging = custom_init_logger(log_dir='log', stdout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:57.081286Z",
     "start_time": "2020-07-09T07:38:57.072474Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cfg = get_args(**Cfg)\n",
    "cfg.classes = 1 ## hardcode num_classes\n",
    "\n",
    "cfg.batch = 8\n",
    "cfg.subdivisions = 2\n",
    "cfg.TRAIN_EPOCHS = 3000\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# torch.cuda.set_device(1)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cfg.gpu\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T07:38:59.277475Z",
     "start_time": "2020-07-09T07:38:58.680164Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Config: \n",
      "{'batch': 8, 'subdivisions': 2, 'width': 416, 'height': 416, 'channels': 3, 'momentum': 0.949, 'decay': 0.0005, 'angle': 0, 'saturation': 1.1, 'exposure': 1.1, 'hue': 0.1, 'learning_rate': 0.001, 'burn_in': 1000, 'max_batches': 500500, 'steps': [400000, 450000], 'policy': [400000, 450000], 'scales': [0.1, 0.1], 'cutmix': 0, 'mosaic': 1, 'letter_box': 0, 'jitter': 0.2, 'classes': 1, 'track': 0, 'w': 416, 'h': 416, 'flip': 1, 'blur': 0, 'gaussian': 0, 'boxes': 60, 'TRAIN_EPOCHS': 3000, 'train_label': 'train.txt', 'val_label': 'data/val.txt', 'TRAIN_OPTIMIZER': 'adam', 'mixup': 3, 'checkpoints': 'checkpoints', 'TRAIN_TENSORBOARD_DIR': 'log', 'load': 'C:\\\\Users\\\\Deployment\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-784f90a6-d391-481a-b906-c1b7625c3afd.json', 'gpu': '-1', 'dataset_dir': None, 'pretrained': None, 'iou_type': 'iou', 'keep_checkpoint_max': 10}\n"
     ]
    }
   ],
   "source": [
    "model = Yolov4(cfg.pretrained,n_classes=cfg.classes)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model.to(device=device)\n",
    "\n",
    "print(\"Training Config: \")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-09T07:39:01.055Z"
    },
    "code_folding": [],
    "hide_input": false,
    "hide_output": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000:   3%| | 4/121 [00:01<00:46,  2.52img\n",
      "Val: Epoch 1:  99%|▉| 120/121 [00:10<00:00, 11.80i\n",
      "Epoch 2/3000:   3%| | 4/121 [00:01<00:51,  2.27img\n",
      "Val: Epoch 2:  79%|▊| 96/121 [00:08<00:02, 11.50im\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "torch.manual_seed(20)\n",
    "np.random.seed(20)\n",
    "random.seed(20)\n",
    "\n",
    "\n",
    "try:\n",
    "    custom_train(\n",
    "        train_dataset=dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        model=model,\n",
    "        config=cfg,\n",
    "        epochs=cfg.TRAIN_EPOCHS,\n",
    "        device=device,\n",
    "        log_step=100)\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model.state_dict(), 'INTERRUPTED.pth')\n",
    "    logging.info('Saved interrupt')\n",
    "    try:\n",
    "        sys.exit(0)\n",
    "    except SystemExit:\n",
    "        os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tensor board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:04:58.360561Z",
     "start_time": "2020-07-09T03:04:58.121Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "torch.manual_seed(20)\n",
    "np.random.seed(20)\n",
    "random.seed(20)\n",
    "\n",
    "[len(dataset[i][1]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## VisualizeResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T04:22:22.613588Z",
     "start_time": "2020-07-09T04:22:21.298389Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_path = \"./weight/Yolov4_epoch327.pth\"\n",
    "image_path = \"/Users/ckh/OneDrive - Default Directory/Hui_Wan/Sample_Anno_Data_NPT/18_GSKE_Sungai_Pin_4_ytl_0114.JPG\"\n",
    "\n",
    "## load model\n",
    "model = Yolov4(cfg.pretrained,n_classes=cfg.classes, inference=True)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:41:34.472908Z",
     "start_time": "2020-07-09T06:41:34.274360Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "## load image\n",
    "# img = cv2.imread(image_path)\n",
    "# img = cv2.resize(img, (416, 416), cv2.INTER_LINEAR)\n",
    "\n",
    "img_raw = val_dataset[80][0]\n",
    "img = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "img = img.transpose(2, 0, 1)\n",
    "img = torch.from_numpy(img).div(255.0)\n",
    "img = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:41:58.521620Z",
     "start_time": "2020-07-09T06:41:35.633240Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## predict \n",
    "out = model(img)\n",
    "\n",
    "\n",
    "## result \n",
    "## convert result\n",
    "## visulize and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:42:00.475245Z",
     "start_time": "2020-07-09T06:41:59.467666Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "out_box = out[out[:,:,4] > 0.1]\n",
    "bboxes = out_box[:,0:4] * 1000\n",
    "x,y,w,h = bboxes[:,0], bboxes[:,1], bboxes[:,2]/2, bboxes[:,3]/2\n",
    "                                                            \n",
    "x1, x2, y1, y2 = x-w, x+w, y-h, y+h\n",
    "\n",
    "img = img_raw.copy()\n",
    "border = 2\n",
    "font_size = 2\n",
    "for b in zip(x1,y1,x2,y2):\n",
    "    b = list(map(int,b))\n",
    "#     print(b)\n",
    "    cv2.rectangle(img, (b[0],b[1]), (b[2],b[3]), (0,0,255), border)\n",
    "    text = \"NPT\" ##self.id_names[b[4]]\n",
    "    cv2.putText(img, text, (b[0],b[1]), cv2.FONT_HERSHEY_PLAIN, font_size, (255,0,0), border)\n",
    "    \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:03:46.599220Z",
     "start_time": "2020-07-15T09:03:46.584125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"NOTEBOOK = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"NOTEBOOK = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:03:47.165479Z",
     "start_time": "2020-07-15T09:03:46.766854Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TrainingRunnner.ipynb to exp/nb_TrainingRunnner.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py \"$NOTEBOOK\".ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
