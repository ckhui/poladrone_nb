{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainingRunnner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- setup dataloader\n",
    "- start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:52.731348Z",
     "start_time": "2020-07-06T08:54:52.695842Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:53.694863Z",
     "start_time": "2020-07-06T08:54:52.735814Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "from exp.nb_CustomDataLoader import Detection_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:53.729077Z",
     "start_time": "2020-07-06T08:54:53.696769Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:53.770616Z",
     "start_time": "2020-07-06T08:54:53.736618Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/Users/ckh/Documents/Poladrone/nb/ref/pytorchYOLOv4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:53.805737Z",
     "start_time": "2020-07-06T08:54:53.775085Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch import optim\n",
    "# from tensorboardX import SummaryWriter\n",
    "# import logging\n",
    "# import os, sys\n",
    "# from tqdm import tqdm\n",
    "# # from dataset import Yolo_dataset\n",
    "# # from cfg import Cfg__init\n",
    "# from ref.pytorchYOLOv4.models import Yolov4\n",
    "\n",
    "# import argparse\n",
    "# from easydict import EasyDict as edict\n",
    "# from torch.nn import functional as F\n",
    "\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:54.114905Z",
     "start_time": "2020-07-06T08:54:53.807603Z"
    }
   },
   "outputs": [],
   "source": [
    "from ref.pytorchYOLOv4.train import *\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:54.146684Z",
     "start_time": "2020-07-06T08:54:54.117740Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    images = []\n",
    "    bboxes = []\n",
    "    for i, (img, box) in enumerate(batch):\n",
    "        images.append([img])\n",
    "        \n",
    "        box = np.concatenate((box, [[i]]*len(box)), 1)\n",
    "        bboxes.append(box)\n",
    "        \n",
    "    images = np.concatenate(images, axis=0)\n",
    "    images = images.transpose(0, 3, 1, 2)\n",
    "    images = torch.from_numpy(images).div(255.0)\n",
    "            \n",
    "    bboxes = np.concatenate(bboxes)\n",
    "\n",
    "    bboxes = torch.from_numpy(bboxes)\n",
    "    return images, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:54.214731Z",
     "start_time": "2020-07-06T08:54:54.150380Z"
    },
    "code_folding": [
     22,
     39,
     86
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def custom_train(train_dataset, val_dataset, model, device, config, epochs=5, batch_size=1, save_cp=True, log_step=20, img_scale=0.5):\n",
    "#     train_dataset = Yolo_dataset(config.train_label, config)\n",
    "#     val_dataset = Yolo_dataset(config.val_label, config)\n",
    "\n",
    "    n_train = len(train_dataset)\n",
    "    n_val = len(val_dataset)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch // config.subdivisions, shuffle=True,\n",
    "                              num_workers=4, pin_memory=True, drop_last=True, collate_fn=custom_collate)\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch // config.subdivisions, shuffle=False, num_workers=1,\n",
    "                            pin_memory=True, drop_last=True, collate_fn=custom_collate)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=config.TRAIN_TENSORBOARD_DIR,\n",
    "                           filename_suffix=f'OPT_{config.TRAIN_OPTIMIZER}_LR_{config.learning_rate}_BS_{config.batch}_Sub_{config.subdivisions}_Size_{config.width}',\n",
    "                           comment=f'OPT_{config.TRAIN_OPTIMIZER}_LR_{config.learning_rate}_BS_{config.batch}_Sub_{config.subdivisions}_Size_{config.width}')\n",
    "#     writer.add_images('legend',\n",
    "#                       torch.from_numpy(train_dataset.label2colorlegend2(cfg.DATA_CLASSES).transpose([2, 0, 1])).to(\n",
    "#                           device).unsqueeze(0))\n",
    "    max_itr = config.TRAIN_EPOCHS * n_train\n",
    "    # global_step = cfg.TRAIN_MINEPOCH * n_train\n",
    "    global_step = 0\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {config.batch}\n",
    "        Subdivisions:    {config.subdivisions}\n",
    "        Learning rate:   {config.learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_cp}\n",
    "        Device:          {device.type}\n",
    "        Images size:     {config.width}\n",
    "        Optimizer:       {config.TRAIN_OPTIMIZER}\n",
    "        Dataset classes: {config.classes}\n",
    "        Train label path:{config.train_label}\n",
    "        Pretrained:\n",
    "    ''')\n",
    "\n",
    "    # learning rate setup\n",
    "    def burnin_schedule(i):\n",
    "        if i < config.burn_in:\n",
    "            factor = pow(i / config.burn_in, 4)\n",
    "        elif i < config.steps[0]:\n",
    "            factor = 1.0\n",
    "        elif i < config.steps[1]:\n",
    "            factor = 0.1\n",
    "        else:\n",
    "            factor = 0.01\n",
    "        return factor\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate / config.batch, betas=(0.9, 0.999), eps=1e-08)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, burnin_schedule)\n",
    "\n",
    "    criterion = Custom_Yolo_loss(n_classes=config.classes, device=device, batch=config.batch // config.subdivisions)\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience=6, min_lr=1e-7)\n",
    "    # scheduler = CosineAnnealingWarmRestarts(optimizer, 0.001, 1e-6, 20)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_step = 0\n",
    "\n",
    "        model.train()\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img', ncols=50) as pbar:\n",
    "            for i, batch in enumerate(train_loader):\n",
    "                global_step += 1\n",
    "                epoch_step += 1\n",
    "                images = batch[0]\n",
    "                bboxes = batch[1]\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                bboxes = bboxes.to(device=device)\n",
    "                \n",
    "                bboxes_pred = model(images)\n",
    "                loss, loss_xy, loss_wh, loss_obj, loss_cls, loss_l2 = criterion(bboxes_pred, bboxes)\n",
    "                # loss = loss / config.subdivisions\n",
    "                loss.backward()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if global_step  % config.subdivisions == 0:\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    model.zero_grad()\n",
    "\n",
    "                if global_step % (log_step * config.subdivisions) == 0:\n",
    "                    writer.add_scalar('train/Loss', loss.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_xy', loss_xy.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_wh', loss_wh.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_obj', loss_obj.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_cls', loss_cls.item(), global_step)\n",
    "                    writer.add_scalar('train/loss_l2', loss_l2.item(), global_step)\n",
    "                    writer.add_scalar('lr', scheduler.get_lr()[0] * config.batch, global_step)\n",
    "                    pbar.set_postfix(**{'loss (batch)': loss.item(), 'loss_xy': loss_xy.item(),\n",
    "                                        'loss_wh': loss_wh.item(),\n",
    "                                        'loss_obj': loss_obj.item(),\n",
    "                                        'loss_cls': loss_cls.item(),\n",
    "                                        'loss_l2': loss_l2.item(),\n",
    "                                        'lr': scheduler.get_lr()[0] * config.batch\n",
    "                                        })\n",
    "                    logging.debug('Train step_{}: loss : {},loss xy : {},loss wh : {},'\n",
    "                                  'loss obj : {}ï¼Œloss cls : {},loss l2 : {},lr : {}'\n",
    "                                  .format(global_step, loss.item(), loss_xy.item(),\n",
    "                                          loss_wh.item(), loss_obj.item(),\n",
    "                                          loss_cls.item(), loss_l2.item(),\n",
    "                                          scheduler.get_lr()[0] * config.batch))\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                \n",
    "                break\n",
    "\n",
    "        model.eval()\n",
    "        with tqdm(total=n_val, desc=f'Val: Epoch {epoch + 1}', unit='img', ncols=50) as pbar:\n",
    "            val_loss = 0\n",
    "            for j, batch in enumerate(val_loader):      \n",
    "                images = batch[0]\n",
    "                bboxes = batch[1]\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                bboxes = bboxes.to(device=device)\n",
    "\n",
    "                bboxes_pred = model(images)\n",
    "                loss, loss_xy, loss_wh, loss_obj, loss_cls, loss_l2 = criterion(bboxes_pred, bboxes)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                pbar.set_postfix(val_loss)\n",
    "                break\n",
    "                \n",
    "            if save_cp:\n",
    "                try:\n",
    "                    os.mkdir(config.checkpoints)\n",
    "                    logging.info('Created checkpoint directory')\n",
    "                except OSError:\n",
    "                    pass\n",
    "                torch.save(model.state_dict(), os.path.join(config.checkpoints, f'Yolov4_epoch{epoch + 1}.pth'))\n",
    "                logging.info(f'Checkpoint {epoch + 1} saved !')\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:54.294478Z",
     "start_time": "2020-07-06T08:54:54.217108Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class Custom_Yolo_loss(nn.Module):\n",
    "    def __init__(self, n_classes=80, n_anchors=3, device=None, batch=2):\n",
    "        super(Custom_Yolo_loss, self).__init__()\n",
    "        self.device = device\n",
    "        self.strides = [8, 16, 32]\n",
    "        image_size = 416\n",
    "        self.n_classes = n_classes\n",
    "        self.n_anchors = n_anchors\n",
    "\n",
    "        self.anchors = [[12, 16], [19, 36], [40, 28], [36, 75], [76, 55], [72, 146], [142, 110], [192, 243], [459, 401]]\n",
    "        self.anch_masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "        self.ignore_thre = 0.5\n",
    "\n",
    "        self.masked_anchors, self.ref_anchors, self.grid_x, self.grid_y, self.anchor_w, self.anchor_h = [], [], [], [], [], []\n",
    "\n",
    "        for i in range(3):\n",
    "            all_anchors_grid = [(w / self.strides[i], h / self.strides[i]) for w, h in self.anchors]\n",
    "            masked_anchors = np.array([all_anchors_grid[j] for j in self.anch_masks[i]], dtype=np.float32)\n",
    "            ref_anchors = np.zeros((len(all_anchors_grid), 4), dtype=np.float32)\n",
    "            ref_anchors[:, 2:] = np.array(all_anchors_grid, dtype=np.float32)\n",
    "            ref_anchors = torch.from_numpy(ref_anchors)\n",
    "            # calculate pred - xywh obj cls\n",
    "            fsize = image_size // self.strides[i]\n",
    "            grid_x = torch.arange(fsize, dtype=torch.float).repeat(batch, 3, fsize, 1).to(device)\n",
    "            grid_y = torch.arange(fsize, dtype=torch.float).repeat(batch, 3, fsize, 1).permute(0, 1, 3, 2).to(device)\n",
    "            anchor_w = torch.from_numpy(masked_anchors[:, 0]).repeat(batch, fsize, fsize, 1).permute(0, 3, 1, 2).to(\n",
    "                device)\n",
    "            anchor_h = torch.from_numpy(masked_anchors[:, 1]).repeat(batch, fsize, fsize, 1).permute(0, 3, 1, 2).to(\n",
    "                device)\n",
    "\n",
    "            self.masked_anchors.append(masked_anchors)\n",
    "            self.ref_anchors.append(ref_anchors)\n",
    "            self.grid_x.append(grid_x)\n",
    "            self.grid_y.append(grid_y)\n",
    "            self.anchor_w.append(anchor_w)\n",
    "            self.anchor_h.append(anchor_h)\n",
    "\n",
    "    def build_target(self, pred, labels, batchsize, fsize, n_ch, output_id):\n",
    "\n",
    "        # target assignment\n",
    "        tgt_mask = torch.zeros(batchsize, self.n_anchors, fsize, fsize, 4 + self.n_classes).to(device=self.device)\n",
    "        obj_mask = torch.ones(batchsize, self.n_anchors, fsize, fsize).to(device=self.device)\n",
    "        tgt_scale = torch.zeros(batchsize, self.n_anchors, fsize, fsize, 2).to(self.device)\n",
    "        target = torch.zeros(batchsize, self.n_anchors, fsize, fsize, n_ch).to(self.device)\n",
    "\n",
    "\n",
    "            # labels = labels.cpu().data\n",
    "        # nlabel = (labels.sum(dim=2) > 0).sum(dim=1)  # number of objects\n",
    "\n",
    "        # batches_labels =  labels[:,-1]\n",
    "        # nlabel = [(batches_labels == i).sum() for i in range(batchsize)]\n",
    "\n",
    "        truth_x_all = (labels[:, 2] + labels[:, 0]) / (self.strides[output_id] * 2)\n",
    "        truth_y_all = (labels[:, 3] + labels[:, 1]) / (self.strides[output_id] * 2)\n",
    "        truth_w_all = (labels[:, 2] - labels[:, 0]) / self.strides[output_id]\n",
    "        truth_h_all = (labels[:, 3] - labels[:, 1]) / self.strides[output_id]\n",
    "        truth_i_all = truth_x_all.to(torch.int16).cpu().numpy()\n",
    "        truth_j_all = truth_y_all.to(torch.int16).cpu().numpy()\n",
    "\n",
    "        for b in range(batchsize):\n",
    "\n",
    "            img_index = (labels[:,-1] == b)\n",
    "            n = int(img_index.sum())\n",
    "            if n == 0:\n",
    "                continue\n",
    "\n",
    "            truth_box = torch.zeros(n, 4).to(self.device)\n",
    "            truth_box[:, 2] = truth_w_all[img_index]\n",
    "            truth_box[:, 3] = truth_h_all[img_index]\n",
    "            truth_i = truth_i_all[img_index]\n",
    "            truth_j = truth_j_all[img_index]\n",
    "\n",
    "            # calculate iou between truth and reference anchors\n",
    "            anchor_ious_all = bboxes_iou(truth_box.cpu(), self.ref_anchors[output_id])\n",
    "            best_n_all = anchor_ious_all.argmax(dim=1)\n",
    "            best_n = best_n_all % 3\n",
    "            best_n_mask = ((best_n_all == self.anch_masks[output_id][0]) |\n",
    "                           (best_n_all == self.anch_masks[output_id][1]) |\n",
    "                           (best_n_all == self.anch_masks[output_id][2]))\n",
    "\n",
    "            if sum(best_n_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            truth_box[:, 0] = truth_x_all[img_index]\n",
    "            truth_box[:, 1] = truth_y_all[img_index]\n",
    "\n",
    "            pred_ious = bboxes_iou(pred[b].view(-1, 4), truth_box, xyxy=False)\n",
    "            pred_best_iou, _ = pred_ious.max(dim=1)\n",
    "            pred_best_iou = (pred_best_iou > self.ignore_thre)\n",
    "            pred_best_iou = pred_best_iou.view(pred[b].shape[:3])\n",
    "            # set mask to zero (ignore) if pred matches truth\n",
    "            obj_mask[b] = ~ pred_best_iou\n",
    "\n",
    "            for ti in range(best_n.shape[0]):\n",
    "                if best_n_mask[ti] == 1:\n",
    "                    i, j = truth_i[ti], truth_j[ti]\n",
    "                    a = best_n[ti]\n",
    "                    obj_mask[b, a, j, i] = 1\n",
    "                    tgt_mask[b, a, j, i, :] = 1\n",
    "                    target[b, a, j, i, 0] = truth_x_all[ti] - truth_x_all[ti].to(torch.int16).to(torch.float)\n",
    "                    target[b, a, j, i, 1] = truth_y_all[ti] - truth_y_all[ti].to(torch.int16).to(torch.float)\n",
    "                    target[b, a, j, i, 2] = torch.log(\n",
    "                        truth_w_all[ti] / torch.Tensor(self.masked_anchors[output_id])[best_n[ti], 0] + 1e-16)\n",
    "                    target[b, a, j, i, 3] = torch.log(\n",
    "                        truth_h_all[ti] / torch.Tensor(self.masked_anchors[output_id])[best_n[ti], 1] + 1e-16)\n",
    "                    target[b, a, j, i, 4] = 1\n",
    "                    target[b, a, j, i, 5 + labels[ti, 4].to(torch.int16).cpu().numpy()] = 1\n",
    "                    tgt_scale[b, a, j, i, :] = torch.sqrt(2 - truth_w_all[ti] * truth_h_all[ti] / fsize / fsize)\n",
    "        return obj_mask, tgt_mask, tgt_scale, target\n",
    "\n",
    "    def forward(self, xin, labels=None):\n",
    "        loss, loss_xy, loss_wh, loss_obj, loss_cls, loss_l2 = 0, 0, 0, 0, 0, 0\n",
    "        for output_id, output in enumerate(xin):\n",
    "\n",
    "            batchsize = output.shape[0]\n",
    "            fsize = output.shape[2]\n",
    "\n",
    "            n_ch = 5 + self.n_classes\n",
    "\n",
    "            output = output.view(batchsize, self.n_anchors, n_ch, fsize, fsize)\n",
    "            output = output.permute(0, 1, 3, 4, 2)  # .contiguous()\n",
    "\n",
    "            # logistic activation for xy, obj, cls\n",
    "            output[..., np.r_[:2, 4:n_ch]] = torch.sigmoid(output[..., np.r_[:2, 4:n_ch]])\n",
    "\n",
    "            pred = output[..., :4].clone()\n",
    "            pred[..., 0] += self.grid_x[output_id]\n",
    "            pred[..., 1] += self.grid_y[output_id]\n",
    "            pred[..., 2] = torch.exp(pred[..., 2]) * self.anchor_w[output_id]\n",
    "            pred[..., 3] = torch.exp(pred[..., 3]) * self.anchor_h[output_id]\n",
    "\n",
    "            ## get label for this batch only\n",
    "\n",
    "            obj_mask, tgt_mask, tgt_scale, target = self.build_target(pred, labels, batchsize, fsize, n_ch, output_id)\n",
    "\n",
    "            # loss calculation\n",
    "            output[..., 4] *= obj_mask\n",
    "            output[..., np.r_[0:4, 5:n_ch]] *= tgt_mask\n",
    "            output[..., 2:4] *= tgt_scale\n",
    "\n",
    "            target[..., 4] *= obj_mask\n",
    "            target[..., np.r_[0:4, 5:n_ch]] *= tgt_mask\n",
    "            target[..., 2:4] *= tgt_scale\n",
    "\n",
    "            loss_xy += F.binary_cross_entropy(input=output[..., :2], target=target[..., :2],\n",
    "                                              weight=tgt_scale * tgt_scale, size_average=False)\n",
    "            loss_wh += F.mse_loss(input=output[..., 2:4], target=target[..., 2:4], size_average=False) / 2\n",
    "            loss_obj += F.binary_cross_entropy(input=output[..., 4], target=target[..., 4], size_average=False)\n",
    "            loss_cls += F.binary_cross_entropy(input=output[..., 5:], target=target[..., 5:], size_average=False)\n",
    "            loss_l2 += F.mse_loss(input=output, target=target, size_average=False)\n",
    "\n",
    "        loss = loss_xy + loss_wh + loss_obj + loss_cls\n",
    "\n",
    "        return loss, loss_xy, loss_wh, loss_obj, loss_cls, loss_l2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:54.476176Z",
     "start_time": "2020-07-06T08:54:54.296711Z"
    }
   },
   "outputs": [],
   "source": [
    "from config.config import Cfg\n",
    "data_list = \"/Users/ckh/OneDrive - Default Directory/Hui_Wan/train_npt.txt\"\n",
    "dataset = Detection_dataset(data_list, Cfg)\n",
    "dataset.names\n",
    "\n",
    "\n",
    "## without augmentation\n",
    "val_dataset = Detection_dataset(data_list, Cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:54.511600Z",
     "start_time": "2020-07-06T08:54:54.479311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log file path:log/log_2020-07-06_16-54-54.txt\n"
     ]
    }
   ],
   "source": [
    "logging = init_logger(log_dir='log', stdout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:54:55.125403Z",
     "start_time": "2020-07-06T08:54:54.515370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch': 4,\n",
       " 'subdivisions': 4,\n",
       " 'width': 416,\n",
       " 'height': 416,\n",
       " 'channels': 3,\n",
       " 'momentum': 0.949,\n",
       " 'decay': 0.0005,\n",
       " 'angle': 0,\n",
       " 'saturation': 1.1,\n",
       " 'exposure': 1.1,\n",
       " 'hue': 0.1,\n",
       " 'learning_rate': 0.001,\n",
       " 'burn_in': 1000,\n",
       " 'max_batches': 500500,\n",
       " 'steps': [400000, 450000],\n",
       " 'policy': [400000, 450000],\n",
       " 'scales': [0.1, 0.1],\n",
       " 'cutmix': 0,\n",
       " 'mosaic': 1,\n",
       " 'letter_box': 0,\n",
       " 'jitter': 0.2,\n",
       " 'classes': 10,\n",
       " 'track': 0,\n",
       " 'w': 416,\n",
       " 'h': 416,\n",
       " 'flip': 1,\n",
       " 'blur': 0,\n",
       " 'gaussian': 0,\n",
       " 'boxes': 60,\n",
       " 'TRAIN_EPOCHS': 300,\n",
       " 'train_label': 'train.txt',\n",
       " 'val_label': 'data/val.txt',\n",
       " 'TRAIN_OPTIMIZER': 'adam',\n",
       " 'mixup': 3,\n",
       " 'checkpoints': 'checkpoints',\n",
       " 'TRAIN_TENSORBOARD_DIR': 'log',\n",
       " 'load': '/Users/ckh/Library/Jupyter/runtime/kernel-72e222bf-ce46-4854-ae48-5969e6741f25.json',\n",
       " 'gpu': '-1',\n",
       " 'dataset_dir': None,\n",
       " 'pretrained': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = get_args(**Cfg)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cfg.gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "model = Yolov4(cfg.pretrained,n_classes=cfg.classes)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model.to(device=device)\n",
    "\n",
    "print()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:56:27.527775Z",
     "start_time": "2020-07-06T08:54:55.135924Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:   0%|       | 0/121 [00:00<?, ?img/s]/Users/ckh/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 1/300:   1%| | 1/121 [00:07<15:14,  7.62s/img]\n",
      "Val: Epoch 1:   1%| | 1/121 [00:02<05:02,  2.52s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-8-3802d58da4f7>\u001b[0m(116)\u001b[0;36mcustom_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    114 \u001b[0;31m        \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Val: Epoch {epoch + 1}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    115 \u001b[0;31m            \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 116 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    117 \u001b[0;31m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m                    \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> images\n",
      "tensor([[[[0.5055, 0.5049, 0.3761,  ..., 0.5975, 0.7681, 0.7043],\n",
      "          [0.5069, 0.3955, 0.3990,  ..., 0.5764, 0.7685, 0.6946],\n",
      "          [0.4425, 0.4493, 0.4258,  ..., 0.6659, 0.6819, 0.6776],\n",
      "          ...,\n",
      "          [0.8296, 0.8716, 0.6901,  ..., 0.6741, 0.6741, 0.6741],\n",
      "          [0.8763, 0.7872, 0.8570,  ..., 0.6741, 0.6741, 0.6741],\n",
      "          [0.7838, 0.6868, 0.8184,  ..., 0.6741, 0.6741, 0.6741]],\n",
      "\n",
      "         [[0.6172, 0.6479, 0.5419,  ..., 0.5936, 0.7474, 0.6753],\n",
      "          [0.6260, 0.5344, 0.5632,  ..., 0.5789, 0.7478, 0.6660],\n",
      "          [0.5696, 0.5904, 0.5796,  ..., 0.6800, 0.6638, 0.6512],\n",
      "          ...,\n",
      "          [0.7452, 0.7871, 0.6056,  ..., 0.6893, 0.6893, 0.6893],\n",
      "          [0.7756, 0.7092, 0.7790,  ..., 0.6893, 0.6893, 0.6893],\n",
      "          [0.6835, 0.5851, 0.7091,  ..., 0.6893, 0.6893, 0.6893]],\n",
      "\n",
      "         [[0.4184, 0.4181, 0.2760,  ..., 0.5329, 0.7031, 0.6423],\n",
      "          [0.4063, 0.2961, 0.2863,  ..., 0.5167, 0.7034, 0.6290],\n",
      "          [0.3259, 0.3335, 0.2949,  ..., 0.6058, 0.6146, 0.6086],\n",
      "          ...,\n",
      "          [0.7530, 0.8053, 0.6238,  ..., 0.6148, 0.6148, 0.6148],\n",
      "          [0.7932, 0.7335, 0.8032,  ..., 0.6148, 0.6148, 0.6148],\n",
      "          [0.7000, 0.5932, 0.7264,  ..., 0.6148, 0.6148, 0.6148]]]])\n",
      "ipdb> bboxes\n",
      "tensor([[114.5560, 139.4607, 139.8906, 162.0000,   0.0000,   0.0000],\n",
      "        [156.9080,   0.0000, 205.3364,  38.7427,   0.0000,   0.0000],\n",
      "        [153.0338, 120.1024, 197.1036, 162.0000,   0.0000,   0.0000],\n",
      "        [117.7512, 162.0000, 143.0000, 199.2752,   0.0000,   0.0000],\n",
      "        [ 75.7845, 253.8727, 129.1596, 307.2478,   0.0000,   0.0000],\n",
      "        [ 31.3732, 343.9177,  70.8952, 383.4398,   0.0000,   0.0000],\n",
      "        [289.8767, 238.1352, 334.9503, 283.2087,   0.0000,   0.0000],\n",
      "        [209.2406, 312.1551, 248.5249, 351.4394,   0.0000,   0.0000]],\n",
      "       dtype=torch.float64)\n",
      "ipdb> c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Val: Epoch 1:   2%| | 2/121 [01:11<44:21, 22.37s/img]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-8-3802d58da4f7>\u001b[0m(116)\u001b[0;36mcustom_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    114 \u001b[0;31m        \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Val: Epoch {epoch + 1}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    115 \u001b[0;31m            \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 116 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    117 \u001b[0;31m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m                    \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1b17a375bfce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         log_step=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INTERRUPTED.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3802d58da4f7>\u001b[0m in \u001b[0;36mcustom_train\u001b[0;34m(train_dataset, val_dataset, model, device, config, epochs, batch_size, save_cp, log_step, img_scale)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Val: Epoch {epoch + 1}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3802d58da4f7>\u001b[0m in \u001b[0;36mcustom_train\u001b[0;34m(train_dataset, val_dataset, model, device, config, epochs, batch_size, save_cp, log_step, img_scale)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Val: Epoch {epoch + 1}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "torch.manual_seed(20)\n",
    "np.random.seed(20)\n",
    "random.seed(20)\n",
    "\n",
    "\n",
    "try:\n",
    "    custom_train(\n",
    "        train_dataset=dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        model=model,\n",
    "        config=cfg,\n",
    "        epochs=cfg.TRAIN_EPOCHS,\n",
    "        device=device,\n",
    "        log_step=1)\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model.state_dict(), 'INTERRUPTED.pth')\n",
    "    logging.info('Saved interrupt')\n",
    "    try:\n",
    "        sys.exit(0)\n",
    "    except SystemExit:\n",
    "        os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:56:27.552678Z",
     "start_time": "2020-07-06T08:54:52.728Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "torch.manual_seed(20)\n",
    "np.random.seed(20)\n",
    "random.seed(20)\n",
    "\n",
    "[len(dataset[i][1]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:56:27.564296Z",
     "start_time": "2020-07-06T08:54:52.731Z"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"NOTEBOOK = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:56:27.578519Z",
     "start_time": "2020-07-06T08:54:52.733Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python notebook2script.py \"$NOTEBOOK\".ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T08:56:27.589601Z",
     "start_time": "2020-07-06T08:54:52.736Z"
    }
   },
   "outputs": [],
   "source": [
    "%%javascripddt\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"NOTEBOOK = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);\n",
    "\n",
    "!python notebook2script.py \"$NOTEBOOK\".ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
