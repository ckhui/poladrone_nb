{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "- [param] read dataset list, list of jpg\n",
    "    -  assume has corresponding xml file beside\n",
    "- [param] .name file for label hashing\n",
    "- read bbbox data\n",
    "- build dict [image path: annotation]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:53:09.539484Z",
     "start_time": "2020-07-09T02:53:09.530508Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install easydict\n",
    "# !pip3 install fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:53:10.309285Z",
     "start_time": "2020-07-09T02:53:09.548610Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import random\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:53:10.943746Z",
     "start_time": "2020-07-09T02:53:10.311133Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from exp.voc_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:53:10.998344Z",
     "start_time": "2020-07-09T02:53:10.948182Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:53:11.032875Z",
     "start_time": "2020-07-09T02:53:11.000812Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from exp.nb_RandomHelper import rand_uniform_strong, rand_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:53:11.068122Z",
     "start_time": "2020-07-09T02:53:11.035153Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def show(path):### Pytorch Dataset\n",
    "\n",
    "    img = cv2.imread(path)\n",
    "    imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:53:11.150828Z",
     "start_time": "2020-07-09T02:53:11.074385Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def fill_truth_detection(bboxes, num_boxes, classes, flip, dx, dy, sx, sy, net_w, net_h):\n",
    "    if bboxes.shape[0] == 0:\n",
    "        return [], 10000\n",
    "    \n",
    "    bboxes[:,[0,2]] -= dx\n",
    "    bboxes[:,[1,3]] -= dy\n",
    "    \n",
    "#     ## remove boxes which center is outside \n",
    "#     center = bboxes[:,[0,1]] + (bboxes[:,[2,3]] - bboxes[:,[0,1]] / 2)\n",
    "#     keep_indexes = np.logical_and(center >= [0,0], center <= [sx,sy]).all(1)\n",
    "#     bboxes = bboxes[keep_indexes]\n",
    "    \n",
    "#     if bboxes.shape[0] == 0:\n",
    "#         return [], 10000\n",
    "\n",
    "    ## remove invalid classes\n",
    "    bboxes = bboxes[np.logical_and(bboxes[:,4] >= 0, bboxes[:,4] < classes)]\n",
    "\n",
    "    ## Apply Scale\n",
    "    bboxes[:, 0:4] *= [net_w / sx, net_h / sy, net_w / sx, net_h / sy]\n",
    "    \n",
    "    ## Remove extra small boxes\n",
    "    min_sizes = (bboxes[:,[2,3]]- bboxes[:,[0,1]]).min(1)\n",
    "#     indexes = min_sizes > 20\n",
    "#     bboxes = bboxes[indexes]\n",
    "#     min_sizes = min_sizes[indexes]\n",
    "    \n",
    "#     if bboxes.shape[0] == 0:\n",
    "#         return [], 10000\n",
    "    \n",
    "    min_w_h = min_sizes.min()\n",
    "\n",
    "    if flip:\n",
    "        bboxes[:, [2,0]] = net_w - bboxes[:, [0,2]]\n",
    "    \n",
    "    return bboxes, min_w_h\n",
    "\n",
    "def rect_intersection(a, b):\n",
    "    minx = max(a[0], b[0])\n",
    "    miny = max(a[1], b[1])\n",
    "\n",
    "    maxx = min(a[2], b[2])\n",
    "    maxy = min(a[3], b[3])\n",
    "    return [minx, miny, maxx, maxy]\n",
    "\n",
    "def image_data_augmentation(mat, w, h, pleft, ptop, swidth, sheight, flip, dhue, dsat, dexp, gaussian_noise, blur,\n",
    "                            truth):\n",
    "    try:\n",
    "        img = mat\n",
    "        oh, ow, _ = img.shape\n",
    "        pleft, ptop, swidth, sheight = int(pleft), int(ptop), int(swidth), int(sheight)\n",
    "        # crop\n",
    "        src_rect = [pleft, ptop, swidth + pleft, sheight + ptop]  # x1,y1,x2,y2\n",
    "        img_rect = [0, 0, ow, oh]\n",
    "        new_src_rect = rect_intersection(src_rect, img_rect)  # 交集\n",
    "\n",
    "        dst_rect = [max(0, -pleft), max(0, -ptop), max(0, -pleft) + new_src_rect[2] - new_src_rect[0],\n",
    "                    max(0, -ptop) + new_src_rect[3] - new_src_rect[1]]\n",
    "        # cv2.Mat sized\n",
    "\n",
    "        if (src_rect[0] == 0 and src_rect[1] == 0 and src_rect[2] == img.shape[0] and src_rect[3] == img.shape[1]):\n",
    "            sized = cv2.resize(img, (w, h), cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            cropped = np.zeros([sheight, swidth, 3])\n",
    "            cropped[:, :, ] = np.mean(img, axis=(0, 1))\n",
    "\n",
    "            cropped[dst_rect[1]:dst_rect[3], dst_rect[0]:dst_rect[2]] = \\\n",
    "                img[new_src_rect[1]:new_src_rect[3], new_src_rect[0]:new_src_rect[2]]\n",
    "\n",
    "            # resize\n",
    "            sized = cv2.resize(cropped, (w, h), cv2.INTER_LINEAR)\n",
    "\n",
    "        # flip\n",
    "        if flip:\n",
    "            # cv2.Mat cropped\n",
    "            sized = cv2.flip(sized, 1)  # 0 - x-axis, 1 - y-axis, -1 - both axes (x & y)\n",
    "\n",
    "        # HSV augmentation\n",
    "        # cv2.COLOR_BGR2HSV, cv2.COLOR_RGB2HSV, cv2.COLOR_HSV2BGR, cv2.COLOR_HSV2RGB\n",
    "        if dsat != 1 or dexp != 1 or dhue != 0:\n",
    "            if img.shape[2] >= 3:\n",
    "                hsv_src = cv2.cvtColor(sized.astype(np.float32), cv2.COLOR_RGB2HSV)  # RGB to HSV\n",
    "                hsv = cv2.split(hsv_src)\n",
    "                hsv[1] *= dsat\n",
    "                hsv[2] *= dexp\n",
    "                hsv[0] += 179 * dhue\n",
    "                hsv_src = cv2.merge(hsv)\n",
    "                sized = np.clip(cv2.cvtColor(hsv_src, cv2.COLOR_HSV2RGB), 0, 255)  # HSV to RGB (the same as previous)\n",
    "            else:\n",
    "                sized *= dexp\n",
    "\n",
    "        if blur:\n",
    "            if blur == -1:\n",
    "                ## Apply blur with kernal 17\n",
    "                dst = cv2.GaussianBlur(sized, (17, 17), 0)\n",
    "                # cv2.bilateralFilter(sized, dst, 17, 75, 75)\n",
    "                \n",
    "                ## Copy Object from before blur\n",
    "                sized_h,sized_w,_ = sized.shape\n",
    "                for b in truth:\n",
    "                    print(b)\n",
    "                    left = (b.x - b.w / 2.) * sized_h\n",
    "                    width = b.w * sized_h\n",
    "                    top = (b.y - b.h / 2.) * sized_w\n",
    "                    height = b.h * sized_w\n",
    "                    \n",
    "                    x1,x2 = max(int(left),0), min(int(left + width), sized_w)\n",
    "                    y1,y2 = max(int(top),0), min(int(top + height), sized_h)\n",
    "                    dst[x1:x2, y1:y2] = sized[x1:x2, y1:y2]\n",
    "\n",
    "            else:\n",
    "                ksize = (blur//2) * 2 + 1 # 2->3, 3->3, 4->5\n",
    "                dst = cv2.GaussianBlur(sized, (ksize, ksize), 0)\n",
    "            sized = dst\n",
    "\n",
    "        if gaussian_noise:\n",
    "            noise = np.array(sized.shape)\n",
    "            gaussian_noise = max(0, min(gaussian_noise, 127))  # range ~ [0,127]\n",
    "            cv2.randn(noise, 0, gaussian_noise)  # mean and variance\n",
    "            sized = np.clip(sized + nois, 0, 255)\n",
    "    except Exception as e:\n",
    "        print(\"OpenCV can't augment image: \" + str(w) + \" x \" + str(h))\n",
    "        print(e)\n",
    "        sized = mat\n",
    "\n",
    "    return sized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:53:11.203176Z",
     "start_time": "2020-07-09T02:53:11.158296Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def filter_truth(bboxes, dx, dy, sx, sy, xd, yd):\n",
    "    if len(bboxes) == 0:\n",
    "        return bboxes\n",
    "        \n",
    "    bboxes[:,[0,2]] -= dx\n",
    "    bboxes[:,[1,3]] -= dy\n",
    "    \n",
    "    ## remove boxes which center is outside \n",
    "    center = bboxes[:,[0,1]] + ((bboxes[:,[2,3]] - bboxes[:,[0,1]]) / 2)\n",
    "    keep_indexes = np.logical_and(center >= [0,0], center <= [sx,sy]).all(1)\n",
    "    bboxes = bboxes[keep_indexes]\n",
    "    \n",
    "    bboxes[:, [0,2]] = np.clip(bboxes[:, [0,2]], 0, sx)\n",
    "    bboxes[:, [1,3]] = np.clip(bboxes[:, [1,3]], 0, sy)    \n",
    "    \n",
    "    bboxes[:,[0,2]] += xd\n",
    "    bboxes[:,[1,3]] += yd\n",
    "    \n",
    "    return bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T02:53:11.247694Z",
     "start_time": "2020-07-09T02:53:11.210681Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def blend_truth_mosaic(out_img, img, bboxes, w, h, cut_x, cut_y, i_mixup,\n",
    "                       left_shift, right_shift, top_shift, bot_shift):\n",
    "    \n",
    "    \n",
    "    left_shift = min(left_shift, w - cut_x)\n",
    "    top_shift = min(top_shift, h - cut_y)\n",
    "    right_shift = min(right_shift, cut_x)\n",
    "    bot_shift = min(bot_shift, cut_y)\n",
    "    \n",
    "    if i_mixup == 0:\n",
    "        bboxes = filter_truth(bboxes, left_shift, top_shift, cut_x, cut_y, 0, 0)\n",
    "        out_img[:cut_y, :cut_x] = img[top_shift:top_shift + cut_y, left_shift:left_shift + cut_x]\n",
    "    if i_mixup == 1:\n",
    "        bboxes = filter_truth(bboxes, cut_x - right_shift, top_shift, w - cut_x, cut_y, cut_x, 0)\n",
    "        out_img[:cut_y, cut_x:] = img[top_shift:top_shift + cut_y, cut_x - right_shift:w - right_shift]\n",
    "    if i_mixup == 2:\n",
    "        bboxes = filter_truth(bboxes, left_shift, cut_y - bot_shift, cut_x, h - cut_y, 0, cut_y)\n",
    "        out_img[cut_y:, :cut_x] = img[cut_y - bot_shift:h - bot_shift, left_shift:left_shift + cut_x]\n",
    "    if i_mixup == 3:\n",
    "        bboxes = filter_truth(bboxes, cut_x - right_shift, cut_y - bot_shift, w - cut_x, h - cut_y, cut_x, cut_y)\n",
    "        out_img[cut_y:, cut_x:] = img[cut_y - bot_shift:h - bot_shift, cut_x - right_shift:w - right_shift]\n",
    "\n",
    "    return out_img, bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T04:21:20.786711Z",
     "start_time": "2020-07-09T04:21:20.741715Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def resize_gt(gt, srcSize=(1000,1000), targetSize = (416,416)):\n",
    "    ratio_h = targetSize[0] / srcSize[0]\n",
    "    ratio_w = targetSize[1] / srcSize[1]\n",
    "    \n",
    "    gt = gt * [ratio_w, ratio_h, ratio_w, ratio_h, 1]\n",
    "    \n",
    "    return gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T04:21:36.379110Z",
     "start_time": "2020-07-09T04:21:36.295144Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class Detection_dataset(Dataset):\n",
    "    def __init__(self, image_paths, cfg=None, val=False, val_keep_size=False):\n",
    "        super(Detection_dataset, self).__init__()\n",
    "        \n",
    "        self.val_mode = val\n",
    "        self.val_keep_size = val_keep_size\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        names = [\"palm1_npt\", \"palm1_byt\", \"palm2_mtl\"]\n",
    "        self.names = {name:i for i,name in enumerate(names)}\n",
    "        self.id_names = {i: name for i,name in enumerate(names)}\n",
    "        \n",
    "        truth = {}\n",
    "        f = open(image_paths, 'r', encoding='utf-8')\n",
    "        for line in f.readlines():\n",
    "            path = line.rstrip()\n",
    "            truth[path] = self.read_annot(path)         \n",
    "        self.truth = truth\n",
    "        \n",
    "    def read_annot(self, jpg):\n",
    "        parts = jpg.split('.')\n",
    "        parts[-1] = 'xml'\n",
    "        xml = '.'.join(parts)\n",
    "        \n",
    "        annots = PascalVocReader(xml).getAnnot()\n",
    "        for annot in annots:\n",
    "            uid = self.names.get(annot[-1], None)\n",
    "            if uid == None:\n",
    "                uid = self.extend_name(annot[-1])\n",
    "            annot[-1] = uid\n",
    "        return annots\n",
    "        \n",
    "    def extend_name(self, name):\n",
    "        newId = len(self.names.keys())\n",
    "        self.names[name] = newId\n",
    "        self.id_names[newId] = name\n",
    "        print(\"Added Missing Name: %d, %s\"%(newId, name))\n",
    "        return newId\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        ## Setup\n",
    "        mosaic = True\n",
    "        # w, h = self.cfg.w, self.cfg.h\n",
    "        w, h = 416,416                \n",
    "        \n",
    "        r1, r2, r3, r4, r_scale = 0, 0, 0, 0, 0\n",
    "        dhue, dsat, dexp, flip, blur = 0, 0, 0, 0, 0\n",
    "        gaussian_noise = 0\n",
    "        \n",
    "        out_img = np.zeros([h, w, 3])\n",
    "        out_bboxes = []\n",
    "        \n",
    "        ## augmentation\n",
    "        if mosaic and not self.val_mode: \n",
    "            min_offset = 0.2\n",
    "            max_offset = 1 - min_offset\n",
    "            cut_x = random.randint(int(w * min_offset), int(w * max_offset))\n",
    "            cut_y = random.randint(int(h * min_offset), int(h * max_offset))\n",
    "            \n",
    "            temp_out_bboxes = []\n",
    "            for i in range(4):\n",
    "                if i == 0:\n",
    "                    img_path = list(self.truth.keys())[index]\n",
    "                else:\n",
    "                    img_path = random.choice(list(self.truth.keys()))\n",
    "                    \n",
    "                bboxes = np.array(self.truth.get(img_path), dtype=np.float)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                    \n",
    "                oh, ow, oc = img.shape\n",
    "                dh, dw, dc = np.array(np.array([oh, ow, oc]) * self.cfg.jitter, dtype=np.int)\n",
    "                dhue = rand_uniform_strong(-self.cfg.hue, self.cfg.hue)\n",
    "                dsat = rand_scale(self.cfg.saturation)\n",
    "                dexp = rand_scale(self.cfg.exposure)\n",
    "                \n",
    "                flip = random.randint(0, 1) if self.cfg.flip else 0\n",
    "                \n",
    "                if self.cfg.blur:\n",
    "                    tmp_blur = random.randint(0, 2) \n",
    "                    if tmp_blur == 0:       # 0 - disable\n",
    "                        blur = 0\n",
    "                    elif tmp_blur == 1:     # -1 - blur background, \n",
    "                        blur = -1\n",
    "                    else:                   # n ~ [2,n] - blur with config scale\n",
    "                        blur = max(self.cfg.blur,2)\n",
    "                        \n",
    "                if self.cfg.gaussian:\n",
    "                    gaussian_noise = random.randint(0, 1)\n",
    "                \n",
    "                pleft = random.randint(-dw, dw)\n",
    "                ptop = random.randint(-dh, dh)\n",
    "                \n",
    "                pright = random.randint(-dw, dw)\n",
    "                pbot = random.randint(-dh, dh)\n",
    "                \n",
    "                swidth = ow - pleft - pright\n",
    "                sheight = oh - ptop - pbot\n",
    "                \n",
    "                aspect_ratio = True\n",
    "                if aspect_ratio: ## maintain aspect-ratio:\n",
    "                    if swidth > sheight :\n",
    "                        pright = swidth - ow + pleft\n",
    "                        swidth = sheight\n",
    "                    else:\n",
    "                        pbot = sheight - oh + ptop\n",
    "                        sheight = swidth\n",
    "                \n",
    "                truth, min_w_h = fill_truth_detection(bboxes, self.cfg.boxes, self.cfg.classes, flip, pleft, ptop, swidth,\n",
    "                                                  sheight, self.cfg.w, self.cfg.h)\n",
    "                \n",
    "                if blur>0: \n",
    "                    if min_w_h < 8:  # disable blur if one of the objects is too small\n",
    "                        blur = 0\n",
    "                    else:            # change blur factor according to the min_obj_size\n",
    "                        blur = min(int(min_w_h / 8), blur)\n",
    "                \n",
    "                \n",
    "                ai = image_data_augmentation(img, self.cfg.w, self.cfg.h, pleft, ptop, swidth, sheight, flip,\n",
    "                                         dhue, dsat, dexp, gaussian_noise, blur, truth)\n",
    "                \n",
    "                if flip:\n",
    "                    pleft, pright = pright, pleft\n",
    "\n",
    "                left_shift = int(min(cut_x, max(0, (-int(pleft) * self.cfg.w / swidth))))\n",
    "                top_shift = int(min(cut_y, max(0, (-int(ptop) * self.cfg.h / sheight))))\n",
    "\n",
    "                right_shift = int(min((self.cfg.w - cut_x), max(0, (-int(pright) * self.cfg.w / swidth))))\n",
    "                bot_shift = int(min(self.cfg.h - cut_y, max(0, (-int(pbot) * self.cfg.h / sheight))))\n",
    "\n",
    "                out_img, out_bbox = blend_truth_mosaic(out_img, ai, truth.copy(), self.cfg.w, self.cfg.h, cut_x,\n",
    "                                                       cut_y, i, left_shift, right_shift, top_shift, bot_shift)\n",
    "                temp_out_bboxes.append(out_bbox)\n",
    "                \n",
    "            out_bboxes = [box for bboxes in temp_out_bboxes for box in bboxes]\n",
    "        else:\n",
    "            ## read image and Annot\n",
    "            img_path = list(self.truth.keys())[index]\n",
    "            img = cv2.imread(img_path)\n",
    "            bboxes = np.array(self.truth.get(img_path), dtype=np.float)\n",
    "            \n",
    "            if not self.val_keep_size:\n",
    "                img = cv2.resize(img, (w, h), cv2.INTER_LINEAR)\n",
    "                bboxes = resize_gt(bboxes)\n",
    "                \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            out_img = img\n",
    "            out_bboxes = bboxes        \n",
    "        \n",
    "        ## return: img_tensor, annotation\n",
    "        return out_img, out_bboxes\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.truth.keys())\n",
    "    \n",
    "    def sample(self):\n",
    "        \n",
    "        for i in range(1,4):\n",
    "            index = random.randint(0, len(self)-1)\n",
    "\n",
    "            img_src, bboxes = self[index]\n",
    "            img = np.array(img_src, dtype=np.uint8)\n",
    "\n",
    "            size = min(img.shape[:2])\n",
    "            border = max(size // 200 ,1)\n",
    "            font_size = max(size // 500,1)\n",
    "\n",
    "            for b in bboxes:\n",
    "                b = list(map(int,b))\n",
    "                cv2.rectangle(img, (b[0],b[1]), (b[2],b[3]), (0,0,255), border)\n",
    "                text = self.id_names[b[4]]\n",
    "                cv2.putText(img, text, (b[0],b[1]), cv2.FONT_HERSHEY_PLAIN, font_size, (255,0,0), border)\n",
    "\n",
    "            plt.subplot(2,2,i)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T04:21:42.160481Z",
     "start_time": "2020-07-09T04:21:42.125379Z"
    }
   },
   "outputs": [],
   "source": [
    "from config.config import Cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T04:21:42.710645Z",
     "start_time": "2020-07-09T04:21:42.570136Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ckh/OneDrive - Default Directory/Hui_Wan/train_npt.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a0e4257bff60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# data_list = \"/Users/ckh/OneDrive - Default Directory/Hui_Wan/train.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/Users/ckh/OneDrive - Default Directory/Hui_Wan/train_npt.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDetection_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-c8206d54782f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, image_paths, cfg, val)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtruth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ckh/OneDrive - Default Directory/Hui_Wan/train_npt.txt'"
     ]
    }
   ],
   "source": [
    "# data_list = \"/Users/ckh/OneDrive - Default Directory/Hui_Wan/train.txt\"\n",
    "data_list = \"/Users/ckh/OneDrive - Default Directory/Hui_Wan/train_npt.txt\"\n",
    "dataset = Detection_dataset(data_list, Cfg)\n",
    "dataset.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T04:21:45.501224Z",
     "start_time": "2020-07-09T04:21:43.253181Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"# Dataset :\", len(dataset.truth))\n",
    "\n",
    "print(\"Sample: \")\n",
    "key = list(dataset.truth.keys())[0]\n",
    "print(key)\n",
    "print(\"Items: \")\n",
    "print(dataset.truth[key])\n",
    "\n",
    "dataset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T04:21:49.601676Z",
     "start_time": "2020-07-09T04:21:47.963597Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = Detection_dataset(data_list, Cfg, val=True)\n",
    "val_dataset.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:50:43.333103Z",
     "start_time": "2020-07-15T09:50:43.314190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"NOTEBOOK = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"NOTEBOOK = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T09:50:44.323159Z",
     "start_time": "2020-07-15T09:50:43.959246Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted CustomDataLoader.ipynb to exp/nb_CustomDataLoader.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py \"$NOTEBOOK\".ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "364.4px",
    "left": "1703px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
