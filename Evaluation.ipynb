{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:45:58.590976Z",
     "start_time": "2020-07-16T09:45:58.511494Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:45:58.688749Z",
     "start_time": "2020-07-16T09:45:58.594468Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:45:58.688749Z",
     "start_time": "2020-07-16T09:45:58.594468Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:45:58.723346Z",
     "start_time": "2020-07-16T09:45:58.692019Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "import os, sys\n",
    "# base = \"/Users/ckh/Documents/Poladrone/nb\"\n",
    "base = \"D:/YoloV5_Hui/poladrone_nb\"\n",
    "sys.path.append(base + \"/ref/pytorchYOLOv4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:45:58.764713Z",
     "start_time": "2020-07-16T09:45:58.727134Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "from exp.nb_TrainingRunnner import *\n",
    "from exp.nb_LoggingModule import custom_init_logger\n",
    "from config.config import Cfg\n",
    "\n",
    "from ref.pytorchYOLOv4.tool.utils import nms_cpu, bbox_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:45:59.003912Z",
     "start_time": "2020-07-16T09:45:58.770276Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data_list = \"/Users/ckh/OneDrive - Default Directory/Hui_Wan/train_npt.txt\"\n",
    "# data_list = \"/Users/ckh/OneDrive - Default Directory/Hui_Wan/npt_test.txt\"\n",
    "# data_list = \"D:/YoloV5_Hui/Dataset/train_npt.txt\"\n",
    "data_list = \"D:/YoloV5_Hui/Dataset/val2.txt\"\n",
    "\n",
    "val_dataset = Detection_dataset(data_list, Cfg, val=True, val_keep_size=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:45:59.043190Z",
     "start_time": "2020-07-16T09:45:59.006423Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def load_model(weight_path, n_classes=1):\n",
    "    ## load model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Load: {weight_path} | Device: {device}')\n",
    "    \n",
    "    model = Yolov4(None, n_classes=n_classes, inference=True)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=[0])\n",
    "    model.to(device=device)\n",
    "    model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:46:00.430304Z",
     "start_time": "2020-07-16T09:45:59.046699Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"./checkpoints/Yolov4_epoch10.pth\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:46:00.532477Z",
     "start_time": "2020-07-16T09:46:00.461636Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def preprocess_image(img_raw, targetSize=416):\n",
    "    img = cv2.resize(img_raw, (targetSize,targetSize))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).div(255.0)\n",
    "    img = img.unsqueeze(0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:46:00.719036Z",
     "start_time": "2020-07-16T09:46:00.633221Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def predict_img(model, img, size):\n",
    "    img = preprocess_image(img, targetSize=size)\n",
    "    img = img.cuda()\n",
    "    out = model(img)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:46:00.769591Z",
     "start_time": "2020-07-16T09:46:00.724463Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# !mkdir inference\n",
    "\n",
    "def inference_index(index, size, postfix=\"\", show=False, save=False):\n",
    "    img_raw, gt = val_dataset[index]\n",
    "    out = predict_img(model, img_raw, size)\n",
    "    if show:\n",
    "        out_img = visualize_yolo(img_raw, out, gt=gt, targetSize=size, conf_thresh=0.01)\n",
    "    if save:\n",
    "        cv2.imwrite(\"./inference/%d%s.jpg\"%(index, postfix), out_img)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:46:00.830699Z",
     "start_time": "2020-07-16T09:46:00.775467Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def post_processing(img, conf_thresh, nms_thresh, output):\n",
    "\n",
    "    # anchors = [12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
    "    # num_anchors = 9\n",
    "    # anchor_masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "    # strides = [8, 16, 32]\n",
    "    # anchor_step = len(anchors) // num_anchors\n",
    "\n",
    "#     t1 = time.time()\n",
    "\n",
    "    if type(output).__name__ != 'ndarray':\n",
    "        output = output.cpu().detach().numpy()\n",
    "\n",
    "    # [batch, num, 4]\n",
    "    box_array = output[:, :, :4]\n",
    "\n",
    "    # [batch, num, num_classes]\n",
    "    confs = output[:, :, 4:]\n",
    "\n",
    "    # [batch, num, num_classes] --> [batch, num]\n",
    "    max_conf = np.max(confs, axis=2)\n",
    "    max_id = np.argmax(confs, axis=2)\n",
    "\n",
    "#     t2 = time.time()\n",
    "\n",
    "    bboxes_batch = []\n",
    "    for i in range(box_array.shape[0]):\n",
    "       \n",
    "        argwhere = max_conf[i] > conf_thresh\n",
    "        l_box_array = box_array[i, argwhere, :]\n",
    "        l_max_conf = max_conf[i, argwhere]\n",
    "        l_max_id = max_id[i, argwhere]\n",
    "\n",
    "        keep = nms_cpu(l_box_array, l_max_conf, nms_thresh)\n",
    "        \n",
    "        bboxes = []\n",
    "        if (keep.size > 0):\n",
    "            l_box_array = l_box_array[keep, :]\n",
    "            l_max_conf = l_max_conf[keep]\n",
    "            l_max_id = l_max_id[keep]\n",
    "\n",
    "            for j in range(l_box_array.shape[0]):\n",
    "                bboxes.append([l_box_array[j, 0], l_box_array[j, 1], l_box_array[j, 2], l_box_array[j, 3], l_max_conf[j], l_max_conf[j], l_max_id[j]])\n",
    "        \n",
    "        bboxes_batch.append(bboxes)\n",
    "\n",
    "#     t3 = time.time()\n",
    "\n",
    "#     print('-----------------------------------')\n",
    "#     print('       max and argmax : %f' % (t2 - t1))\n",
    "#     print('                  nms : %f' % (t3 - t2))\n",
    "#     print('Post processing total : %f' % (t3 - t1))\n",
    "#     print('-----------------------------------')\n",
    "    \n",
    "    return bboxes_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:46:00.627086Z",
     "start_time": "2020-07-16T09:46:00.560025Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def visualize_yolo(img_raw, yolo_out, conf_thresh= 0.5, gt=None, targetSize=1000):\n",
    "    out = yolo_out\n",
    "    img = img_raw.copy()\n",
    "    \n",
    "    border = 2\n",
    "    font_size = 1.2\n",
    "    img = cv2.resize(img, (targetSize,targetSize))\n",
    "        \n",
    "    if not out.size == 0:\n",
    "        out_box = out[out[:,:,4] > conf_thresh]\n",
    "        bboxes = out_box[:,0:4] * targetSize\n",
    "        conf = out_box[:,4]\n",
    "        x,y,w,h = bboxes[:,0], bboxes[:,1], bboxes[:,2]/2, bboxes[:,3]/2\n",
    "\n",
    "        x1, x2, y1, y2 = x-w, x+w, y-h, y+h\n",
    "\n",
    "        for b in zip(x1,y1,x2,y2, conf):\n",
    "            c = b[4]\n",
    "            b = list(map(int,b))\n",
    "            cv2.rectangle(img, (b[0],b[1]), (b[2],b[3]), (0,0,255), border)\n",
    "            text = \"NPT %.1f\"%(c*100) ##self.id_names[b[4]]\n",
    "            cv2.putText(img, text, (b[0],b[1]), cv2.FONT_HERSHEY_PLAIN, font_size, (255,0,0), border)\n",
    "        \n",
    "    if not gt is None:\n",
    "        gt_box = gt[:,:4] * (targetSize / img_raw.shape[0])\n",
    "        for g in gt_box:\n",
    "            b = list(map(int,g))\n",
    "            cv2.rectangle(img, (b[0],b[1]), (b[2],b[3]), (0,255,255), border)\n",
    "            text = \"GT\" ##self.id_names[b[4]]\n",
    "            cv2.putText(img, text, (b[2],b[1]), cv2.FONT_HERSHEY_PLAIN, font_size, (0,255,255), border)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:46:00.916843Z",
     "start_time": "2020-07-16T09:46:00.832930Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def bbox_iogt(box1, box2, x1y1x2y2=True):\n",
    "    '''\n",
    "    box1: GT\n",
    "    '''\n",
    "    \n",
    "    # print('iou box1:', box1)\n",
    "    # print('iou box2:', box2)\n",
    "\n",
    "    if x1y1x2y2:\n",
    "        mx = min(box1[0], box2[0])\n",
    "        Mx = max(box1[2], box2[2])\n",
    "        my = min(box1[1], box2[1])\n",
    "        My = max(box1[3], box2[3])\n",
    "        w1 = box1[2] - box1[0]\n",
    "        h1 = box1[3] - box1[1]\n",
    "        w2 = box2[2] - box2[0]\n",
    "        h2 = box2[3] - box2[1]\n",
    "    else:\n",
    "        w1 = box1[2]\n",
    "        h1 = box1[3]\n",
    "        w2 = box2[2]\n",
    "        h2 = box2[3]\n",
    "\n",
    "        mx = min(box1[0], box2[0])\n",
    "        Mx = max(box1[0] + w1, box2[0] + w2)\n",
    "        my = min(box1[1], box2[1])\n",
    "        My = max(box1[1] + h1, box2[1] + h2)\n",
    "    uw = Mx - mx\n",
    "    uh = My - my\n",
    "    cw = w1 + w2 - uw\n",
    "    ch = h1 + h2 - uh\n",
    "    carea = 0\n",
    "    if cw <= 0 or ch <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    carea = cw * ch\n",
    "#     uarea = area1 + area2 - carea\n",
    "    uarea = area1 \n",
    "    return carea / uarea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:02:18.023508Z",
     "start_time": "2020-07-16T09:02:17.970271Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def score(gt, nms):\n",
    "    if nms.size == 0:\n",
    "        return 0, len(gt)\n",
    "        \n",
    "    box_gt = gt/1000\n",
    "\n",
    "    x1 = nms[:,:,0] - nms[:,:,2]\n",
    "    y1 = nms[:,:,1] - nms[:,:,3]\n",
    "    x2 = nms[:,:,0] + nms[:,:,2]\n",
    "    y2 = nms[:,:,1] + nms[:,:,3]\n",
    "    box_predict = np.concatenate([x1,y1,x2,y2], axis=0).T\n",
    "\n",
    "    iogt = [[bbox_iogt(g, p) for g in box_gt] for p in box_predict]\n",
    "    iogt = np.max(iogt, axis=0)\n",
    "\n",
    "    total = len(iogt)\n",
    "    score = sum(iogt > 0.5)\n",
    "    \n",
    "    return score, total\n",
    "\n",
    "def recall(gt, nms):\n",
    "    \n",
    "    if nms.size == 0:\n",
    "        if len(gt) == 0:\n",
    "            return 1, 1\n",
    "        return 0, 1\n",
    "        \n",
    "    box_gt = gt/1000\n",
    "\n",
    "    x1 = nms[:,:,0] - nms[:,:,2]\n",
    "    y1 = nms[:,:,1] - nms[:,:,3]\n",
    "    x2 = nms[:,:,0] + nms[:,:,2]\n",
    "    y2 = nms[:,:,1] + nms[:,:,3]\n",
    "    box_predict = np.concatenate([x1,y1,x2,y2], axis=0).T\n",
    "\n",
    "    iogt = [[bbox_iogt(g, p) for g in box_gt] for p in box_predict]\n",
    "    iogt = np.max(iogt, axis=1)\n",
    "\n",
    "    total = len(iogt)\n",
    "    score = sum(iogt > 0.8)\n",
    "    \n",
    "    return score, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Predict - Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Predict Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Comparing  input Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T13:52:15.303780Z",
     "start_time": "2020-07-15T13:48:29.615913Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Try with different size\n",
    "index = 180\n",
    "for s in range(0,300,16):\n",
    "    size = 608+s\n",
    "    inference_index(index,size=size, postfix=\"_%d\"%(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T11:33:54.604366Z",
     "start_time": "2020-07-15T11:33:54.288403Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualize_yolo(img_raw, out, conf_thresh=0.01, gt=gt, targetSize=416)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Comparing NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T04:04:43.973935Z",
     "start_time": "2020-07-16T04:04:25.116437Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## inference\n",
    "index=180\n",
    "out = predict_index(index, 720)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T04:45:19.399712Z",
     "start_time": "2020-07-16T04:45:18.589135Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Comparing NMS\n",
    "nms_box = post_processing(None, 0.01,0.5, out)\n",
    "nms = np.array(nms_box)\n",
    "plt.subplot(121)\n",
    "out_img = visualize_yolo(val_dataset[index][0], nms, 0, gt=val_dataset[index][1], targetSize=416)\n",
    "\n",
    "nms_box = post_processing(None, 0.3,0.5, out)\n",
    "nms = np.array(nms_box)\n",
    "plt.subplot(122)\n",
    "out_img = visualize_yolo(val_dataset[index][0], nms, 0, gt=val_dataset[index][1], targetSize=416)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Flow - Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:47:10.907551Z",
     "start_time": "2020-07-16T09:47:10.853455Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def benchmark_size(size):\n",
    "    \n",
    "    pt = []\n",
    "    count = []\n",
    "    t = []\n",
    "    for index in range(len(val_dataset)):\n",
    "        try:\n",
    "            print(index, end=\" \")\n",
    "            ## inference\n",
    "            img_raw, gt = val_dataset[index]\n",
    "\n",
    "            t1 = time.time()\n",
    "            out = predict_img(model, img_raw, size)\n",
    "            t2 = time.time()\n",
    "            t.append(t2 - t1)\n",
    "\n",
    "            ## NMS\n",
    "            nms_box = post_processing(None, 0.01,0.5, out)\n",
    "            nms = np.array(nms_box)\n",
    "\n",
    "            p, c = score(gt, nms)\n",
    "            pt.append(p)\n",
    "            count.append(c)\n",
    "        except:\n",
    "            print(\"Error\", index)\n",
    "\n",
    "    inference_time = np.mean(t)\n",
    "    score_pre_img = (np.array(pt) / np.array(count)).mean()\n",
    "    score_all = np.sum(pt) / np.sum(count)\n",
    "\n",
    "    return inference_time, score_pre_img, score_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = \"/Users/ckh/OneDrive - Default Directory/Hui_Wan/npt_test.txt\"\n",
    "data_list = \"D:/YoloV5_Hui/Dataset/val2.txt\"\n",
    "val_dataset = Detection_dataset(data_list, Cfg, val=True, val_keep_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"./weight/Yolov4_epoch1707.pth\"\n",
    "model_path = \"../Train1/checkpoints/Yolov4_epoch900.pth\"\n",
    "model = load_model(model_path)\n",
    "model.eval()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:50:04.984772Z",
     "start_time": "2020-07-16T09:49:52.468564Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get size\n",
    "logging = custom_init_logger(\"Train2_size_score_2.txt\")\n",
    "\n",
    "for size in range(320,900,32):\n",
    "    logging.info(f\"Size : {size}\")\n",
    "    time_taken, score_img, score_all = benchmark_size(size)\n",
    "    logging.info(f\"\"\"\n",
    "                 Time : {time_taken} / image\n",
    "                 Score per image: {score_img}\n",
    "                 Score total : {score_all}\n",
    "                 \"\"\")\n",
    "    logging.info(f\"{size},{time_taken},{score_img},{score_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def benchmark_threshold(size):\n",
    "    \n",
    "    pt = []\n",
    "    count = []\n",
    "    recall_score = []\n",
    "    pred_count = []\n",
    "    t = []\n",
    "    for index in range(len(val_dataset)):\n",
    "        try:\n",
    "            print(index, end=\" \")\n",
    "            ## inference\n",
    "            img_raw, gt = val_dataset[index]\n",
    "\n",
    "            t1 = time.time()\n",
    "            out = predict_img(model, img_raw, size)\n",
    "            t2 = time.time()\n",
    "            t.append(t2 - t1)\n",
    "\n",
    "            ## NMS\n",
    "            ps = []\n",
    "            cs = []\n",
    "            rs = []\n",
    "            pcs = []\n",
    "            for i in range(1,10):\n",
    "                thresh = i * 0.1\n",
    "                \n",
    "                nms_box = post_processing(None, thresh,0.5, out)\n",
    "                nms = np.array(nms_box)\n",
    "                p, c = score(gt, nms)\n",
    "                r, pc = recall(gt, nms)\n",
    "                ps.append(p)\n",
    "                cs.append(c)\n",
    "                rs.append(r)\n",
    "                pcs.append(pc)\n",
    "                \n",
    "            pt.append(ps)\n",
    "            count.append(cs)\n",
    "            recall_score.append(rs)\n",
    "            pred_count.append(pcs)\n",
    "        except:\n",
    "            print(\"Error\", index)\n",
    "            \n",
    "    pt = np.array(pt)\n",
    "    count = np.array(count)\n",
    "    \n",
    "    recall_score = np.array(recall_score)\n",
    "    pred_count = np.array(pred_count)\n",
    "\n",
    "    inference_time = np.mean(t)\n",
    "    score_pre_img = (pt / count).mean(axis=0)\n",
    "    score_all = np.sum(pt, axis=0) / np.sum(count, axis=0)\n",
    "    \n",
    "    recall_pre_img = (recall_score / pred_count).mean(axis=0)\n",
    "    recall_all = np.sum(recall_score, axis=0) / np.sum(pred_count, axis=0)\n",
    "\n",
    "    return inference_time, score_pre_img, score_all, recall_pre_img, recall_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get threshold\n",
    "logging = custom_init_logger(\"train2_treshold_full_3.txt\")\n",
    "\n",
    "# for size in [416,736,768,800]:\n",
    "for size in range(320,900,32):\n",
    "    logging.info(f\"Size : {size}\")\n",
    "    time_taken, score_img, score_all, recall_img, recall_all = benchmark_threshold(size)\n",
    "#     logging.info(f\"\"\"\n",
    "#                  Time : {time_taken} / image\n",
    "#                  Score per image: {score_img}\n",
    "#                  Score total : {score_all}\n",
    "#                  \"\"\")\n",
    "    logging.info(f\"{size},{time_taken},{score_img},{score_all},{recall_img},{recall_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def benchmark_model(m, size):\n",
    "    \n",
    "    pt = []\n",
    "    count = []\n",
    "    t = []\n",
    "    recall_score = []\n",
    "    pred_count = []\n",
    "    \n",
    "    for index in range(len(val_dataset)):\n",
    "        try:\n",
    "            print(index, end=\" \")\n",
    "            ## inference\n",
    "            img_raw, gt = val_dataset[index]\n",
    "\n",
    "            t1 = time.time()\n",
    "            out = predict_img(m, img_raw, size)\n",
    "            t2 = time.time()\n",
    "            t.append(t2 - t1)\n",
    "\n",
    "            ## NMS\n",
    "            ps = []\n",
    "            cs = []\n",
    "            rs = []\n",
    "            pcs = []\n",
    "            for i in range(1,10):\n",
    "                thresh = i * 0.1\n",
    "\n",
    "                nms_box = post_processing(None, thresh,0.5, out)\n",
    "                nms = np.array(nms_box)\n",
    "                p, c = score(gt, nms)\n",
    "                r, pc = recall(gt, nms)\n",
    "                ps.append(p)\n",
    "                cs.append(c)\n",
    "                rs.append(r)\n",
    "                pcs.append(pc)\n",
    "\n",
    "            pt.append(ps)\n",
    "            count.append(cs)\n",
    "            recall_score.append(rs)\n",
    "            pred_count.append(pcs)\n",
    "        except:\n",
    "            print(\"Error\", index)\n",
    "            \n",
    "    pt = np.array(pt)\n",
    "    count = np.array(count)\n",
    "    recall_score = np.array(recall_score)\n",
    "    pred_count = np.array(pred_count)\n",
    "\n",
    "    inference_time = np.mean(t)\n",
    "    score_pre_img = (pt / count).mean(axis=0)\n",
    "    score_all = np.sum(pt, axis=0) / np.sum(count, axis=0)\n",
    "    \n",
    "    recall_pre_img = (recall_score / pred_count).mean(axis=0)\n",
    "    recall_all = np.sum(recall_score, axis=0) / np.sum(pred_count, axis=0)\n",
    "\n",
    "    return inference_time, score_pre_img, score_all, recall_pre_img, recall_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging = custom_init_logger(\"train2_result_model_recall_2.txt\")\n",
    "\n",
    "for i in range(100,901,50): ##[1000, 1500, 1800, 2700, 3000]:\n",
    "    model_path = \"../Train1/checkpoints/Yolov4_epoch%d.pth\"%(i)\n",
    "    model = load_model(model_path)\n",
    "    model.eval()\n",
    "    \n",
    "    logging.info(f\"Model : {i}\")\n",
    "    for size in [416,608,640,672, 704]:\n",
    "        logging.info(f\"Size : {size}\")\n",
    "        time_taken, score_img, score_all, recall_img, recall_all = benchmark_model(model, size)\n",
    "#         logging.info(f\"\"\"\n",
    "#                      Time : {time_taken} / image\n",
    "#                      Score per image: {score_img}\n",
    "#                      Score total : {score_all}\n",
    "#                      \"\"\")\n",
    "        logging.info(f\"{size},{time_taken},{score_img},{score_all},{recall_img},{recall_all}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:50:08.653833Z",
     "start_time": "2020-07-16T09:50:08.612620Z"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"NOTEBOOK = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T09:50:09.865837Z",
     "start_time": "2020-07-16T09:50:09.442481Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python notebook2script.py \"$NOTEBOOK\".ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
